{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Для начала посмотрим на наши данные, нужно понять с чем мы работаем","metadata":{"id":"y0sILquw9rta"}},{"cell_type":"markdown","source":"### Подключим все необходимые библиотеки","metadata":{"id":"zvLceESzwbFT"}},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nplt.style.use('ggplot')\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing  import LabelEncoder\nfrom sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import balanced_accuracy_score, accuracy_score, mean_absolute_error\nfrom collections import Counter\nimport re\nimport nltk\n#import pymorphy2\nfrom ast import literal_eval\nimport gensim\nimport math","metadata":{"id":"nDvz0qXduEAo","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n### Поля данных\n\n* warehouse_id - идентификатор магазина\n* product_id - идентификатор продукта\n* date - дата\n* quantity - кол-во продаж\n* id - уникальный идентификатор строки\n\n ","metadata":{"id":"iu4vGS5Cvg7t"}},{"cell_type":"code","source":"train_data = pd.read_csv(\"../input/grocery-sales-forecast/train.csv\")\nprint(train_data.shape)\ntrain_data.head(16)","metadata":{"id":"2zA5SS10ubK2","outputId":"a30be221-b8f7-4c61-e4d0-d22bdcab75ae","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Посмотрим на количество товаров и на их id","metadata":{"id":"si_RR9QI2FKc"}},{"cell_type":"code","source":"product_id = train_data.sort_values(by=['product_id'])['product_id'].unique()\nprint(len(product_id))\nprint(product_id[:5])","metadata":{"id":"Cq8zKmj61peJ","outputId":"d2bbc4b3-a9fd-4e4d-bf94-9adc2c5589e7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Посмотрим на тестовую выборку и сделаем некоторые выводы","metadata":{"id":"LdS8FI152Uq-"}},{"cell_type":"code","source":"test_data = pd.read_csv(\"../input/grocery-sales-forecast/test.csv\")\nprint(test_data.shape)\ntest_data.head(15)","metadata":{"id":"U6r9koVw1U4v","outputId":"197ed252-17d4-4cb3-8c8d-08c983c45b98","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Сразу хочется посмотреть на warehouse_id и на product_id, так как при разных product_id будут проблемы\n","metadata":{"id":"xwmQURwI2eYt"}},{"cell_type":"code","source":"product_test_id = test_data.sort_values(by=['product_id'])['product_id'].unique()\nprint(len(product_test_id))\nprint(product_test_id[:5])\nprint(len(set(product_test_id == product_id)))  # Все значения совпадают, проблем нет","metadata":{"id":"l0VUR9qi24CG","outputId":"1129c484-9d15-492a-ba05-8d9c77170433","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"warehouse_id = test_data['warehouse_id'].unique()\nprint(len(warehouse_id))  # Всего два магазина","metadata":{"id":"-IWoYqit4DxJ","outputId":"e3c92f9d-7882-4177-8727-e734d73a72ab","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### В нашем случае всего два магазина и все значения id товаров совпадают. Проблем с данными нет.","metadata":{"id":"vTI_Y9i_4pS5"}},{"cell_type":"markdown","source":"### Посмотрим на simple submission","metadata":{"id":"uTgj_VsfxXhq"}},{"cell_type":"code","source":"simple_data = pd.read_csv(\"../input/grocery-sales-forecast/sub.csv\")\nprint(simple_data.shape)\nsimple_data.head()","metadata":{"id":"TpjF2xQmubNF","outputId":"a6e816a4-f210-476d-beec-66e1ad46098b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Разделение данных на train / test","metadata":{"id":"j_6BD0caL1NT"}},{"cell_type":"markdown","source":"### Итак, суть задачи ясна. Проблем пока не обнаружено, поэтому разделяем нашу train выборку и начинаем реализовывать идеи","metadata":{"id":"7ChXzyoFFiun"}},{"cell_type":"code","source":"'''\n# Это плохой способ разделять данные в нашем случае!\nX_train, X_test, y_train, y_test = train_test_split(train_data.drop('quantity', axis=1), train_data[['quantity']], test_size=0.1945, random_state=42)\nprint(X_train.head(3))\nprint(X_test.head(3))\nprint(y_train.head(3))\nprint(y_test.head(3))\n'''","metadata":{"id":"mxPa36_cF4aj","outputId":"167db0d3-7856-4780-9807-053b92415dc9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Необходимо понимать, что в данных есть пропуски. Это видно по X_train","metadata":{"id":"dG9t1jXNJwDu"}},{"cell_type":"code","source":"train_data = train_data.sort_values(by=['date', 'product_id'])\nX_train = train_data.drop('quantity', axis=1)\ny_train = train_data['quantity']\nX_train","metadata":{"id":"ytFxX5QKIJK6","outputId":"934874cc-7332-4648-83d8-767dbede6e79","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Таким образом имеем отсортированные по дате и id данные. Идея деления:\n\n*   Находим границу последних n дней\n*   Делим на train / test по этой границе\n\n","metadata":{"id":"aRUO6LsXKPL4"}},{"cell_type":"code","source":"# n = 5  # 2021-04-08 - 5 = 2021-04-03 -- Граница\nX_train = train_data.where(train_data['date'] < '2021-04-03').dropna().drop('quantity', axis=1)\ny_train = train_data.where(train_data['date'] < '2021-04-03').dropna()['quantity']\nX_test = train_data.where(train_data['date'] >= '2021-04-03').dropna().drop('quantity', axis=1)\ny_test = train_data.where(train_data['date'] >= '2021-04-03').dropna()['quantity']\nprint(X_train.head(3))\nprint(X_test.head(3))\nprint(y_train.head(3))\nprint(y_test.head(3))","metadata":{"id":"ODcvGYQDLamn","outputId":"da657525-0ef4-44c2-8964-e8d298677888","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Первая идея: дни недели","metadata":{"id":"Tdp6u4Xr9pih"}},{"cell_type":"markdown","source":"### Суть идеи заключается в том, чтобы в каждом магазине найти некие зависимости в соотношении проданный товар/день недели, далее на основе этих зависимостей седлать прогноз","metadata":{"id":"-cgXVZaf-HLb"}},{"cell_type":"markdown","source":"\n\n---\n\n\n\n","metadata":{"id":"c5zncwz3E-rK"}},{"cell_type":"markdown","source":"### Для начала создадим словарь: дата - день недели","metadata":{"id":"xjes_eBAE3N9"}},{"cell_type":"code","source":"data_ = pd.Series(pd.to_datetime(train_data['date'].unique()))\n\n# print(data_, type(data_))\ndata_week = data_.dt.day_name()\n# print(data_week)\ndate2week = dict(zip(train_data['date'].unique(), data_week))\nprint(date2week)","metadata":{"id":"sv86LFbfubPK","outputId":"46a45b88-40cd-4b1c-ea35-688fb09d0f26","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Далее создадим словарь, где key = warehouse_id + product_id, а value = новый словарь с key = день недели и value = массив числа продаж","metadata":{"id":"Rk4PKxmpRG2C"}},{"cell_type":"code","source":"my_dict = {}\n# k = 0\nfor product_info, product_quantity in tqdm(zip(X_train[['warehouse_id', 'product_id', 'date']].values, y_train)):\n    '''\n    product_info[0] - warehouse_id - идентификатор магазина\n    product_info[1] - product_id - идентификатор продукта\n    product_info[2] - date - дата\n    product_quantity - quantity - кол-во продаж\n    '''\n    my_id = str(product_info[0]) + str(product_info[1])\n    # print(my_id, product_info[0], product_info[1])\n    if my_id in my_dict:\n        if date2week[product_info[2]] in my_dict[my_id]:\n            my_dict[my_id][date2week[product_info[2]]].append(product_quantity)\n        else:\n             my_dict[my_id][date2week[product_info[2]]] = [product_quantity]\n    else:\n        my_dict[my_id] = {}\n        my_dict[my_id][date2week[product_info[2]]] = [product_quantity]\n# my_dict","metadata":{"id":"zyOv4TJESB1w","outputId":"69fc0df6-3984-499c-caa5-81c3595ca16f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Теперь для тестовой выборки будем смотреть в этот словарь и искать ответ в зависимости от данных словаря","metadata":{"id":"UuCSUhEKW7ey"}},{"cell_type":"code","source":"answer_round, answer_floor, answer_ceil = [], [], []\nnice_product, bad_product = 0, 0\nfor product_info in tqdm(X_test[['warehouse_id', 'product_id', 'date']].values):\n    my_id_first = str(product_info[0]) + str(product_info[1])\n    my_id_second = date2week[product_info[2]]\n    try:\n        my_array = my_dict[my_id_first][my_id_second]  # Если данных нет в словаре \n        nice_product += 1\n    except:\n        bad_product += 1\n        my_array = []\n    if len(my_array) < 1:\n        answer_round.append(1)\n        answer_floor.append(1)\n        answer_ceil.append(1)\n    else:  # Попробуем среднее\n        answer_round.append(round(sum(my_array) / len(my_array)))\n        answer_floor.append(math.floor(sum(my_array) / len(my_array)))\n        answer_ceil.append(math.ceil(sum(my_array) / len(my_array)))\nprint()\nprint(nice_product, bad_product)\n# print(len(answer), len(y_test))\nprint(mean_absolute_error(y_test, answer_round))\nprint(mean_absolute_error(y_test, answer_floor))\nprint(mean_absolute_error(y_test, answer_ceil))","metadata":{"id":"7B_2-NDfubRJ","outputId":"aa5e8775-6138-4864-d910-ba55a2e1705c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Показывает достаточно неплохой результат. Причём округление в большую сторону даёт лучший результат. Его и буду использовать. ","metadata":{"id":"FccBgHAZcV2T"}},{"cell_type":"code","source":"data_ = pd.Series(pd.to_datetime(test_data['date'].unique()))\n\n# print(data_, type(data_))\ndata_week = data_.dt.day_name()\n# print(data_week)\ndate2week = dict(zip(test_data['date'].unique(), data_week))\nprint(date2week)","metadata":{"id":"_pPOhq_hgbwX","outputId":"cac798e8-b52a-4e5a-aa65-d480c1c12c46","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"answer_ceil = []\nnice_product, bad_product = 0, 0\ndata_2 = pd.Series(pd.to_datetime(test_data['date'].unique()))\nfor product_info in tqdm(test_data[['warehouse_id', 'product_id', 'date']].values):\n    #print()\n    #print(product_info)\n    #break\n    my_id_first = str(float(product_info[0])) + str(float(product_info[1]))\n    my_id_second = date2week[product_info[2]]\n    try:\n        my_array = my_dict[my_id_first][my_id_second]  # Если данных нет в словаре \n        nice_product += 1\n    except:\n        bad_product += 1\n        my_array = []\n    if len(my_array) < 3:  # Если товар в определённый день недели купили пару раз, то логично предположить, что его не купят вовсе\n        answer_ceil.append(0)\n\n    else:  \n        answer_ceil.append(math.ceil(sum(my_array) / len(my_array)))\nprint()\nprint(nice_product, bad_product)\nprint(len(answer_ceil), len(simple_data))\n","metadata":{"id":"gB6zTGxwubTN","outputId":"fa39bf8a-cbdc-4836-8a05-3cf920f86be9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Result_table = pd.read_csv(\"/content/drive/MyDrive/Sales_Forecasting/sub.csv\")\n#Result_table['quantity'] = pd.Series(answer_ceil)\n#Result_table[[\"id\", \"quantity\"]].to_csv(\"FINAL.csv\", index=False)","metadata":{"id":"wbL0HToBubVa","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Score = 0.46886 \n### Мягко говоря - ужасно...\n","metadata":{"id":"AeYKuyaYnk6C"}},{"cell_type":"markdown","source":"## Выводы после первой идеи:\n\n* Корявая обработка нулей, нужно исправлять\n* На основе количества продаж в определённые дни нужно пытаться делать что-то более нетривиальное, чем просто среднее\n* Необходимо изменить test / train выборку, ибо нет учёта нулей\n\n","metadata":{"id":"8DSVQhTQof7T"}},{"cell_type":"markdown","source":"### Начнём исправляться с заполнения нашей выборки нулями\nИдея такая: если в определённый день информации о товаре нет, то значит его купили 0 раз. Это поле должно храниться в выборке.","metadata":{"id":"zyv8GDPLCLyQ"}},{"cell_type":"code","source":"product_id = train_data['product_id'].unique()\ndate = train_data['date'].unique()\nwarehouse_id = train_data['warehouse_id'].unique()\nprint(len(product_id), len(date), len(warehouse_id), len(product_id) * len(date) * len(warehouse_id))","metadata":{"id":"qTw6z9bihtX0","outputId":"70976646-f11a-4062-eb61-e7e2a9fea6f1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Значит у нас должно быть 874608 записей. Не будем вставлять недостоющие записи в таблицу, а сразу будем составлять словарик. Он будет таким же, но более разряженее.","metadata":{"id":"qy0jyzwersSk"}},{"cell_type":"code","source":"my_current_dict = {}\nfor product_info in tqdm(train_data[['warehouse_id', 'product_id', 'date', 'quantity']].values):\n    '''\n    product_info[0] - warehouse_id - идентификатор магазина\n    product_info[1] - product_id - идентификатор продукта\n    product_info[2] - date - дата\n    product_info[3] - quantity - кол-во продаж\n    '''\n    my_id = str(product_info[0]) + str(product_info[1]) + str(product_info[2])\n    my_current_dict[my_id] = product_info[3]\nprint()\nprint(len(my_current_dict))","metadata":{"id":"28OjqYDNqHSB","outputId":"c7c0e70e-ad9f-4a6d-df41-3806e1e8b3e6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Информация есть менее чем о 10% товаров.","metadata":{"id":"AV7MRcZUt5y5"}},{"cell_type":"code","source":"data_ = pd.Series(pd.to_datetime(train_data['date'].unique()))\n\n# print(data_, type(data_))\ndata_week = data_.dt.day_name()\n# print(data_week)\ndate2week = dict(zip(train_data['date'].unique(), data_week))\nprint(date2week)","metadata":{"id":"3T5A7F2Azxz3","outputId":"17752753-ec90-4761-fe9b-d21c7c0deb23","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_huge_dict = {}\nnice_product = 0\nfor id_warehouse in warehouse_id:\n    for id_product in tqdm(product_id):\n        for id_date in date:\n            my_id = str(id_warehouse) + str(id_product) + str(id_date)\n            if my_id in my_current_dict:\n                nice_product += 1\n                if id_warehouse in my_huge_dict:\n                    if id_product in my_huge_dict[id_warehouse]:\n                        if date2week[id_date] in my_huge_dict[id_warehouse][id_product]:\n                            my_huge_dict[id_warehouse][id_product][date2week[id_date]].append(my_current_dict[my_id])\n                        else:\n                            my_huge_dict[id_warehouse][id_product][date2week[id_date]] = [my_current_dict[my_id]]\n                    else:\n                        my_huge_dict[id_warehouse][id_product] = {}\n                        my_huge_dict[id_warehouse][id_product][date2week[id_date]] = [my_current_dict[my_id]]\n                else:\n                    my_huge_dict[id_warehouse] = {}\n                    my_huge_dict[id_warehouse][id_product] = {}\n                    my_huge_dict[id_warehouse][id_product][date2week[id_date]] = [my_current_dict[my_id]]\n            else:\n                if id_warehouse in my_huge_dict:\n                    if id_product in my_huge_dict[id_warehouse]:\n                        if date2week[id_date] in my_huge_dict[id_warehouse][id_product]:\n                            my_huge_dict[id_warehouse][id_product][date2week[id_date]].append(0)\n                        else:\n                            my_huge_dict[id_warehouse][id_product][date2week[id_date]] = [0]\n                    else:\n                        my_huge_dict[id_warehouse][id_product] = {}\n                        my_huge_dict[id_warehouse][id_product][date2week[id_date]] = [0]\n                else:\n                    my_huge_dict[id_warehouse] = {}\n                    my_huge_dict[id_warehouse][id_product] = {}\n                    my_huge_dict[id_warehouse][id_product][date2week[id_date]] = [0]\nprint()\nprint(nice_product)","metadata":{"id":"48aGjp41sQMw","outputId":"a8c1133e-b874-474d-de4c-7cffb542d033","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Проверим себя","metadata":{"id":"6kl1nGigxro3"}},{"cell_type":"code","source":"amount = 0\nset_amount = set()\nfor id_warehouse in warehouse_id:\n    for id_product in tqdm(product_id):\n        for id_date in date:\n            if str(id_warehouse) + str(id_product) + str(date2week[id_date]) not in set_amount:\n                amount += len(my_huge_dict[id_warehouse][id_product][date2week[id_date]])\n                set_amount.add(str(id_warehouse) + str(id_product) + str(date2week[id_date]))\nprint()\nprint(amount)","metadata":{"id":"qjdZF2gHvtsT","outputId":"1cc54cd7-b4d1-48d3-e3aa-e1e681d8e6b4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Размеры совпадают, теперь можно делить на train / test. За границу возьмём 2021-04-01, ровно 7 дней","metadata":{"id":"h3QJb0d11Ica"}},{"cell_type":"code","source":"# Понимаю, что проделываю такую же работу, что и пару ячеек выше. Но хочу сделать акцент на понимании кода\nmy_huge_dict_train = {}\nmy_huge_dict_test = {}\nnice_product = 0\nfor id_warehouse in warehouse_id:\n    for id_product in tqdm(product_id):\n        for id_date in date:\n            if id_date > '2021-04-01':\n                my_id = str(id_warehouse) + str(id_product) + str(id_date)\n                if my_id in my_current_dict:\n                    nice_product += 1\n                    if id_warehouse in my_huge_dict_test:\n                        if id_product in my_huge_dict_test[id_warehouse]:\n                            if date2week[id_date] in my_huge_dict_test[id_warehouse][id_product]:\n                                my_huge_dict_test[id_warehouse][id_product][date2week[id_date]].append(my_current_dict[my_id])\n                            else:\n                                my_huge_dict_test[id_warehouse][id_product][date2week[id_date]] = [my_current_dict[my_id]]\n                        else:\n                            my_huge_dict_test[id_warehouse][id_product] = {}\n                            my_huge_dict_test[id_warehouse][id_product][date2week[id_date]] = [my_current_dict[my_id]]\n                    else:\n                        my_huge_dict_test[id_warehouse] = {}\n                        my_huge_dict_test[id_warehouse][id_product] = {}\n                        my_huge_dict_test[id_warehouse][id_product][date2week[id_date]] = [my_current_dict[my_id]]\n                else:\n                    if id_warehouse in my_huge_dict_test:\n                        if id_product in my_huge_dict_test[id_warehouse]:\n                            if date2week[id_date] in my_huge_dict_test[id_warehouse][id_product]:\n                                my_huge_dict_test[id_warehouse][id_product][date2week[id_date]].append(0)\n                            else:\n                                my_huge_dict_test[id_warehouse][id_product][date2week[id_date]] = [0]\n                        else:\n                            my_huge_dict_test[id_warehouse][id_product] = {}\n                            my_huge_dict_test[id_warehouse][id_product][date2week[id_date]] = [0]\n                    else:\n                        my_huge_dict_test[id_warehouse] = {}\n                        my_huge_dict_test[id_warehouse][id_product] = {}\n                        my_huge_dict_test[id_warehouse][id_product][date2week[id_date]] = [0]\n            else:\n                my_id = str(id_warehouse) + str(id_product) + str(id_date)\n                if my_id in my_current_dict:\n                    nice_product += 1\n                    if id_warehouse in my_huge_dict_train:\n                        if id_product in my_huge_dict_train[id_warehouse]:\n                            if date2week[id_date] in my_huge_dict_train[id_warehouse][id_product]:\n                                my_huge_dict_train[id_warehouse][id_product][date2week[id_date]].append(my_current_dict[my_id])\n                            else:\n                                my_huge_dict_train[id_warehouse][id_product][date2week[id_date]] = [my_current_dict[my_id]]\n                        else:\n                            my_huge_dict_train[id_warehouse][id_product] = {}\n                            my_huge_dict_train[id_warehouse][id_product][date2week[id_date]] = [my_current_dict[my_id]]\n                    else:\n                        my_huge_dict_train[id_warehouse] = {}\n                        my_huge_dict_train[id_warehouse][id_product] = {}\n                        my_huge_dict_train[id_warehouse][id_product][date2week[id_date]] = [my_current_dict[my_id]]\n                else:\n                    if id_warehouse in my_huge_dict_train:\n                        if id_product in my_huge_dict_train[id_warehouse]:\n                            if date2week[id_date] in my_huge_dict_train[id_warehouse][id_product]:\n                                my_huge_dict_train[id_warehouse][id_product][date2week[id_date]].append(0)\n                            else:\n                                my_huge_dict_train[id_warehouse][id_product][date2week[id_date]] = [0]\n                        else:\n                            my_huge_dict_train[id_warehouse][id_product] = {}\n                            my_huge_dict_train[id_warehouse][id_product][date2week[id_date]] = [0]\n                    else:\n                        my_huge_dict_train[id_warehouse] = {}\n                        my_huge_dict_train[id_warehouse][id_product] = {}\n                        my_huge_dict_train[id_warehouse][id_product][date2week[id_date]] = [0]\nprint()\nprint(nice_product)","metadata":{"id":"RP4xI6P_sQKD","outputId":"3cc18769-36d4-4b1d-c82a-40c2b4ad0e8b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"amount = 0\nset_amount = set()\nfor id_warehouse in warehouse_id:\n    for id_product in tqdm(product_id):\n        for id_date in date:\n            if str(id_warehouse) + str(id_product) + str(date2week[id_date]) not in set_amount:\n                amount += len(my_huge_dict_train[id_warehouse][id_product][date2week[id_date]])\n                set_amount.add(str(id_warehouse) + str(id_product) + str(date2week[id_date]))\nprint()\nprint(amount)","metadata":{"id":"fhMKSBHVsQHk","outputId":"5a0dcbd2-7618-418e-c6af-f17ac379c043","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"amount = 0\nset_amount = set()\nfor id_warehouse in warehouse_id:\n    for id_product in tqdm(product_id):\n        for id_date in date:\n            if str(id_warehouse) + str(id_product) + str(date2week[id_date]) not in set_amount:\n                amount += 1  # len(my_huge_dict_test[id_warehouse][id_product][date2week[id_date]])  # Работает, так как у нас всегда массив из одного числа\n                set_amount.add(str(id_warehouse) + str(id_product) + str(date2week[id_date]))\nprint()\nprint(amount)","metadata":{"id":"dDwgQDbHsQFS","outputId":"8c8a97b6-eb39-4eef-d883-49e5a9053d4e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Тестовая выборка занимает всего 5%. Это нужно будет учитывать!","metadata":{"id":"iFsst4df41Nk"}},{"cell_type":"code","source":"right_answer = []\nanswer_round, answer_floor, answer_ceil = [], [], []\nset_amount = set()\nfor id_warehouse in warehouse_id:\n    for id_product in tqdm(product_id):\n        for id_date in date:\n            right_answer.append(my_huge_dict_test[id_warehouse][id_product][date2week[id_date]][0])\n            answer_round.append(round(sum(my_huge_dict_train[id_warehouse][id_product][date2week[id_date]])/len(my_huge_dict_train[id_warehouse][id_product][date2week[id_date]])))\n            answer_floor.append(math.floor(sum(my_huge_dict_train[id_warehouse][id_product][date2week[id_date]])/len(my_huge_dict_train[id_warehouse][id_product][date2week[id_date]])))\n            answer_ceil.append(math.ceil(sum(my_huge_dict_train[id_warehouse][id_product][date2week[id_date]])/len(my_huge_dict_train[id_warehouse][id_product][date2week[id_date]])))\nprint(mean_absolute_error(right_answer, answer_round))\nprint(mean_absolute_error(right_answer, answer_floor))\nprint(mean_absolute_error(right_answer, answer_ceil))","metadata":{"id":"_2AW7RUusQDN","outputId":"f51a244a-0282-4cce-90cf-1ba52af1408e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Не будем повторять ошибок. Вместо ceil возьмём floor","metadata":{"id":"CTzSK37b7vMI"}},{"cell_type":"code","source":"data_ = pd.Series(pd.to_datetime(test_data['date'].unique()))\n\n\n#print(data_, type(data_))\ndata_week = data_.dt.day_name()\n# print(data_week)\ndate2week = dict(zip(test_data['date'].unique(), data_week))\nprint(date2week)","metadata":{"id":"2gozu8J6sQBR","outputId":"4fe52c76-91fe-4e8e-8f80-5bd10d7ddd51","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"answer = []\nfor product_info in tqdm(test_data[['warehouse_id', 'product_id', 'date']].values):\n    id_warehouse = (product_info[0])\n    id_product = (product_info[1])\n    id_date = (product_info[2])\n    #print(id_warehouse)\n    #print(id_product)\n    #print(id_date)\n    #print(my_huge_dict[id_warehouse][id_product][date2week[id_date]])\n    #break\n    answer.append(math.floor(sum(my_huge_dict[id_warehouse][id_product][date2week[id_date]])/len(my_huge_dict[id_warehouse][id_product][date2week[id_date]])))\n    \nprint()\nprint(len(answer), len(simple_data))\n","metadata":{"id":"46-Jmj2e8LGK","outputId":"a1e8fc76-111d-4e18-a308-b5bd1dfafcdc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Result_table = pd.read_csv(\"/content/drive/MyDrive/Sales_Forecasting/sub.csv\")\n#Result_table['quantity'] = pd.Series(answer)\n#Result_table[[\"id\", \"quantity\"]].to_csv(\"FINAL.csv\", index=False)","metadata":{"id":"MKHln6298LIN","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Score = 0.20210\n### Это уже гораздо лучше, но не предел :)","metadata":{"id":"wXuoJ4w1-ysK"}},{"cell_type":"markdown","source":"## Вторая идея: модернизация среднего\n\n","metadata":{"id":"n7Gnnu-PdXnO"}},{"cell_type":"markdown","source":"### Пока оставим идею с днями недели, но будем рассматривать не обычное среднее, а что-то поинтереснее","metadata":{"id":"zUN7NIjt8rs4"}},{"cell_type":"code","source":"data_ = pd.Series(pd.to_datetime(train_data['date'].unique()))\n\n# print(data_, type(data_))\ndata_week = data_.dt.day_name()\n# print(data_week)\ndate2week = dict(zip(train_data['date'].unique(), data_week))\nprint(date2week)","metadata":{"id":"9_byjcVuIDl0","outputId":"cdc9f691-ffc4-4548-864f-7795efb37efe","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import statistics\nfrom scipy import stats as s\n\nright_answer = []\nanswer_round, answer_floor, answer_ceil = [], [], []\nanswer_median, answer_median_low, answer_median_high = [], [], []\nanswer_mode = []\nset_amount = set()\nfor id_warehouse in warehouse_id:\n    for id_product in tqdm(product_id):\n        for id_date in date:\n            right_answer.append(my_huge_dict_test[id_warehouse][id_product][date2week[id_date]][0])\n            answer_round.append(round(sum(my_huge_dict_train[id_warehouse][id_product][date2week[id_date]])/len(my_huge_dict_train[id_warehouse][id_product][date2week[id_date]])))\n            answer_floor.append(math.floor(sum(my_huge_dict_train[id_warehouse][id_product][date2week[id_date]])/len(my_huge_dict_train[id_warehouse][id_product][date2week[id_date]])))\n            answer_ceil.append(math.ceil(sum(my_huge_dict_train[id_warehouse][id_product][date2week[id_date]])/len(my_huge_dict_train[id_warehouse][id_product][date2week[id_date]])))\n\n            answer_median.append(statistics.median(my_huge_dict_train[id_warehouse][id_product][date2week[id_date]]))\n            answer_median_low.append(statistics.median_low(my_huge_dict_train[id_warehouse][id_product][date2week[id_date]]))\n            answer_median_high.append(statistics.median_high(my_huge_dict_train[id_warehouse][id_product][date2week[id_date]]))\n            \n            answer_mode.append(int(s.mode(my_huge_dict_train[id_warehouse][id_product][date2week[id_date]])[0]))\n\nprint(mean_absolute_error(right_answer, answer_round))\nprint(mean_absolute_error(right_answer, answer_floor))\nprint(mean_absolute_error(right_answer, answer_ceil))\n\nprint(mean_absolute_error(right_answer, answer_median))\nprint(mean_absolute_error(right_answer, answer_median_low))\nprint(mean_absolute_error(right_answer, answer_median_high))\n\nprint(mean_absolute_error(right_answer, answer_mode))","metadata":{"id":"elrrBCNX8LLD","outputId":"35a276c6-73ae-4dba-f1ee-01b1e7e460fc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Медиана даёт неплохой результат. Но давайте попробуем нечто сложнее\n","metadata":{"id":"DooPpygZL2BT"}},{"cell_type":"code","source":"def exponential_smoothing(series, alpha):\n    result = [series[0]] # first value is same as series\n    for n in range(1, len(series)):\n        result.append(alpha * series[n] + (1 - alpha) * result[n-1])\n    return result[-1]","metadata":{"id":"ZRqJ89yisP-6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ncur_min = 1\ncur_alpha = 0\n\nfor i in tqdm(range(1, 30)):\n    alpha = i/100\n    right_answer = []\n    answer_exponential_smoothing_round, answer_exponential_smoothing_floor, answer_exponential_smoothing_ceil = [], [], []\n    for id_warehouse in warehouse_id:\n        for id_product in (product_id):\n            for id_date in date:\n                right_answer.append(my_huge_dict_test[id_warehouse][id_product][date2week[id_date]][0])\n                #answer_exponential_smoothing_round.append(round(exponential_smoothing(my_huge_dict_train[id_warehouse][id_product][date2week[id_date]], alpha)))\n                answer_exponential_smoothing_floor.append(math.floor(exponential_smoothing(my_huge_dict_train[id_warehouse][id_product][date2week[id_date]], alpha)))\n                #answer_exponential_smoothing_ceil.append(math.ceil(exponential_smoothing(my_huge_dict_train[id_warehouse][id_product][date2week[id_date]], alpha)))\n    if mean_absolute_error(right_answer, answer_exponential_smoothing_floor) < cur_min:\n        cur_min = mean_absolute_error(right_answer, answer_exponential_smoothing_floor)\n        cur_alpha = alpha\n#print(mean_absolute_error(right_answer, answer_exponential_smoothing_round))\nprint(cur_min, cur_alpha)\n#print(mean_absolute_error(right_answer, answer_exponential_smoothing_ceil))","metadata":{"id":"SVpMs2hSL-7r","outputId":"3143123e-569c-44e0-9038-42075da87230","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Сильного прироста нет, поэтому двойное экспонициальное сглаживание использовать не имеет смысла","metadata":{"id":"pMuFu6_ZRcp0"}},{"cell_type":"code","source":"data_ = pd.Series(pd.to_datetime(test_data['date'].unique()))\n\n\n#print(data_, type(data_))\ndata_week = data_.dt.day_name()\n# print(data_week)\ndate2week = dict(zip(test_data['date'].unique(), data_week))\nprint(date2week)","metadata":{"id":"3p3LXQrVRcTy","outputId":"cf959daf-6a67-4342-e62c-c8ada1f03e11","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"answer = []\nalpha = 0.14\nfor product_info in tqdm(test_data[['warehouse_id', 'product_id', 'date']].values):\n    id_warehouse = (product_info[0])\n    id_product = (product_info[1])\n    id_date = (product_info[2])\n    answer.append(math.floor(exponential_smoothing(my_huge_dict[id_warehouse][id_product][date2week[id_date]], alpha)))\n    \nprint()\nprint(len(answer), len(simple_data))","metadata":{"id":"Zfua-kYbL-43","outputId":"0f541436-2d7b-49f8-f2da-8bbafba5633a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Result_table = pd.read_csv(\"/content/drive/MyDrive/Sales_Forecasting/sub.csv\")\n#Result_table['quantity'] = pd.Series(answer)\n#Result_table[[\"id\", \"quantity\"]].to_csv(\"FINAL_exp.csv\", index=False)","metadata":{"id":"j4DgtZb9L-28","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Score = 0.20085\n### Сильного роста нет. Нужно что-то сложнее...","metadata":{"id":"23Xy6qyZSq0T"}},{"cell_type":"markdown","source":"## Третья идея: учёт соседних дней\n","metadata":{"id":"BBeCSXjjRvZQ"}},{"cell_type":"markdown","source":"### Хочется делать предсказание не только по всем четвергам для предсказания продаж в четверг, но и как-то учитывать соседние дни. Для этого давайте попробуем визуализировать наши данные.\n","metadata":{"id":"0G6y9og4R_8P"}},{"cell_type":"code","source":"first_warehouse = {}\nsecond_warehouse = {}\nnumber_of_products = 10\nset_of_products = set()\n\nfor product_info in tqdm(test_data[['warehouse_id', 'product_id', 'date']].values):\n    id_warehouse = (product_info[0])\n    id_product = (product_info[1])\n    id_date = date2week[(product_info[2])]\n\n    if id_product in set_of_products or len(set_of_products) < number_of_products:\n        set_of_products.add(id_product)\n\n        if id_warehouse == 0:\n            if id_product not in first_warehouse:\n                first_warehouse[id_product] = {}\n                first_warehouse[id_product][id_date] = my_huge_dict[id_warehouse][id_product][id_date]\n\n            else:\n                if id_date not in first_warehouse[id_product]:\n                    first_warehouse[id_product][id_date] = my_huge_dict[id_warehouse][id_product][id_date]\n\n        else:\n            if id_product not in second_warehouse:\n                second_warehouse[id_product] = {}\n                second_warehouse[id_product][id_date] = my_huge_dict[id_warehouse][id_product][id_date]\n\n            else:\n                if id_date not in second_warehouse[id_product]:\n                    second_warehouse[id_product][id_date] = my_huge_dict[id_warehouse][id_product][id_date]\n        \n\n    \nprint()\n\nprint(first_warehouse)\nprint(len(first_warehouse))\nprint(len(first_warehouse[71165]))\n\nprint(second_warehouse)\nprint(len(second_warehouse))\nprint(len(second_warehouse[71165]))","metadata":{"id":"hU4K-O0iL-0q","outputId":"89c0af51-bdbc-4234-83d1-aa4ee0d7815f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# fig, axs = plt.subplots(2, 7, sharex=True, sharey=True)\nfig = plt.figure(figsize=(90, 10))\n\nweek2number = {'Friday': 0, 'Saturday': 1, 'Sunday': 2, 'Monday': 3, 'Tuesday': 4, 'Wednesday': 5, 'Thursday': 6}\nproduct2color = {71165: 'orange', 71170: 'black', 71185: 'blue', 71215: 'green', 71220: 'yellow', 71225: 'red', 71230: 'purple', 71235: 'brown', 71285: 'pink', 71350: 'c'}\ntitle_x = []\nflag_print = True\nfor i in range(1, 20):\n    title_x.append(i)\n\nfor i in first_warehouse.items():\n    for j in i[1].items():\n        position = 171 + week2number[j[0]]\n        ax = fig.add_subplot(position)\n        ax.plot(title_x, j[1], color=product2color[i[0]])\n        if flag_print:\n            print(j[0])\n    flag_print = False\n\n'''\nfor i in second_warehouse.values():\n    for j in i.items():\n        position = 276 + week2number[j[0]]\n        ax = fig.add_subplot(position)\n        ax.plot(title_x, j[1], color='orange', label=j[0])\n'''\n#fig = plt.figure(figsize=(cm_to_inch(15),cm_to_inch(10)))\n#plt.tight_layout()\nplt.show()\n","metadata":{"id":"dplZZxtsL-yr","outputId":"5122c58f-48d8-4b4b-83d9-f4d66ee00343","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Исходя из графиков можно сделать выводы:\n\n*   Имеется **тенденция роста**. Скорее всего это связано с тем, что чем дольше существует магазин, тем больше покупателей в него ходит. Поэтому экспоненциальное сглаживание дало небольшой прирост.\n*   Есть ярко выраженные **выбросы**. Можно попробовать с ними побороться.\n*   В **Saturday** люди закупаются занчительнее чаще, чем в остальные дни. Его в качестве соседнего дня лучше не использовать.\n*   В **Sunday** и **Wednesday** люди покупают продукты подозрительно равномерно.\n\nВсе эти выводы сделаны на основе 10 первых продуктов из первого магазина. Поэтому на последний пункт закроем глаза. А вот с остальными пунктами можно поработать.\n\n\n","metadata":{"id":"6ndnqwq2rbI2"}},{"cell_type":"markdown","source":"### Борьба с выбросами\n\n","metadata":{"id":"BqArP8xHuaIf"}},{"cell_type":"code","source":"data_ = pd.Series(pd.to_datetime(train_data['date'].unique()))\n\n# print(data_, type(data_))\ndata_week = data_.dt.day_name()\n# print(data_week)\ndate2week = dict(zip(train_data['date'].unique(), data_week))\nprint(date2week)","metadata":{"id":"VMWbnhSWvV-5","outputId":"460ec608-d61d-4f78-d0a2-9f2eb3fd1f37","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"right_answer = []\nanswer_round, answer_floor, answer_ceil = [], [], []\nanswer_median, answer_median_low, answer_median_high = [], [], []\nanswer_mode, answer_exp = [], []\nthreshold  = 8\nfor id_warehouse in warehouse_id:\n    for id_product in tqdm(product_id):\n        for id_date in date:\n            data = my_huge_dict_train[id_warehouse][id_product][date2week[id_date]].copy()\n            local_max = 0\n            local_i = 0\n            for i in range(len(data)):\n                if local_max < data[i]:\n                    local_max = data[i]\n                    local_i = i\n\n            data[local_i] = data[-1]  # Удаление максимального элемента\n            data.pop()\n\n\n            right_answer.append(my_huge_dict_test[id_warehouse][id_product][date2week[id_date]][0])\n            answer_round.append(round(sum(data)/len(data)))\n            answer_floor.append(math.floor(sum(data)/len(data)))\n            answer_ceil.append(math.ceil(sum(data)/len(data)))\n\n            answer_median.append(statistics.median(data))\n            answer_median_low.append(statistics.median_low(data))\n            answer_median_high.append(statistics.median_high(data))\n            \n            answer_exp.append(math.floor(exponential_smoothing(data, 0.14)))\n            #answer_mode.append(int(s.mode(data)[0]))\n\nprint(mean_absolute_error(right_answer, answer_round))\nprint(mean_absolute_error(right_answer, answer_floor))\nprint(mean_absolute_error(right_answer, answer_ceil))\n\nprint(mean_absolute_error(right_answer, answer_median))\nprint(mean_absolute_error(right_answer, answer_median_low))\nprint(mean_absolute_error(right_answer, answer_median_high))\n\nprint(mean_absolute_error(right_answer, answer_exp))\n#print(mean_absolute_error(right_answer, answer_mode))","metadata":{"id":"IOUe2eZVvW1f","outputId":"46a761bd-b3c9-455d-a143-644dfa042518","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Пока это лучший результат. Помогло самое обычное удаление максимума.","metadata":{"id":"WFPQgC1y2m-p"}},{"cell_type":"markdown","source":"### Итак, теперь попробуем разбить дни на пары и пытаться делать выводы:\n\n*   Суббота отдельно, как говорил выше\n*   Пятница - воскресенье, как выходные дни\n*   Понедельник - вторник\n*   Среда - чтеверг\n\nЗададим коэффициент, который будет понижать важность второго дня, ибо брать чисто среднее не очень круто\n\n\n","metadata":{"id":"MN3c11O13aYO"}},{"cell_type":"code","source":"cur_min = 1\nbest_alpha = 0\nbest_beta = 0\nfor alpha in tqdm(range(1, 12)):\n    for beta in range(1, 11):\n        if beta <= alpha:\n            right_answer = []\n            answer_exp = []\n            for id_warehouse in warehouse_id:\n                for id_product in (product_id):\n                    for id_date in date:\n                        '''\n                        Friday\n                        Saturday\n                        Sunday\n                        Monday\n                        Tuesday\n                        Wednesday\n                        Thursday\n                        '''\n                        data = my_huge_dict_train[id_warehouse][id_product][date2week[id_date]].copy()\n                        local_max = 0\n                        local_i = 0\n                        for i in range(len(data)):\n                            if local_max < data[i]:\n                                local_max = data[i]\n                                local_i = i\n\n                        data[local_i] = data[-1]  # Удаление максимального элемента\n                        data.pop()\n                        right_answer.append(my_huge_dict_test[id_warehouse][id_product][date2week[id_date]][0])\n                        my_ans_by_day = math.floor(exponential_smoothing(data, 0.14))\n\n                        if date2week[id_date] == 'Saturday':\n                            answer_exp.append(my_ans_by_day)\n                        \n                        #-----------------------------------\n                        elif date2week[id_date] == 'Friday':\n                            data2 = my_huge_dict_train[id_warehouse][id_product]['Sunday'].copy()\n                            my_ans_by_second_day = math.floor(exponential_smoothing(data2, 0.14))\n                            answer_exp.append(((my_ans_by_day * alpha + my_ans_by_second_day * beta) / (alpha + beta)))\n                        \n                        elif date2week[id_date] == 'Sunday':\n                            data2 = my_huge_dict_train[id_warehouse][id_product]['Friday'].copy()\n                            my_ans_by_second_day = math.floor(exponential_smoothing(data2, 0.14))\n                            answer_exp.append((my_ans_by_day * alpha + my_ans_by_second_day * beta) / (alpha + beta))\n                        \n                        #-----------------------------------\n                        elif date2week[id_date] == 'Monday':\n                            data2 = my_huge_dict_train[id_warehouse][id_product]['Tuesday'].copy()\n                            my_ans_by_second_day = math.floor(exponential_smoothing(data2, 0.14))\n                            answer_exp.append((my_ans_by_day * alpha + my_ans_by_second_day * beta) / (alpha + beta))\n                        \n                        elif date2week[id_date] == 'Tuesday':\n                            data2 = my_huge_dict_train[id_warehouse][id_product]['Monday'].copy()\n                            my_ans_by_second_day = math.floor(exponential_smoothing(data2, 0.14))\n                            answer_exp.append((my_ans_by_day * alpha + my_ans_by_second_day * beta) / (alpha + beta))\n                        \n                        #-----------------------------------\n                        elif date2week[id_date] == 'Wednesday':\n                            data2 = my_huge_dict_train[id_warehouse][id_product]['Thursday'].copy()\n                            my_ans_by_second_day = math.floor(exponential_smoothing(data2, 0.14))\n                            answer_exp.append((my_ans_by_day * alpha + my_ans_by_second_day * beta) / (alpha + beta))\n                        \n                        elif date2week[id_date] == 'Thursday':\n                            data2 = my_huge_dict_train[id_warehouse][id_product]['Wednesday'].copy()\n                            my_ans_by_second_day = math.floor(exponential_smoothing(data2, 0.14))\n                            answer_exp.append((my_ans_by_day * alpha + my_ans_by_second_day * beta) / (alpha + beta))\n\n            if mean_absolute_error(right_answer, answer_exp) < cur_min:\n                best_alpha = alpha\n                best_beta = beta\n                cur_min = mean_absolute_error(right_answer, answer_exp)\nprint()\nprint(cur_min, best_alpha, best_beta)\n            #print(mean_absolute_error(right_answer, answer_mode))","metadata":{"id":"rPijPwJjwU97","outputId":"0a892c85-3bff-471e-bced-08fee38031d8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Мда... Ну окей давайте зальём с таким выводом","metadata":{"id":"sgX_S1EEByrh"}},{"cell_type":"code","source":"data_ = pd.Series(pd.to_datetime(test_data['date'].unique()))\n\n\n#print(data_, type(data_))\ndata_week = data_.dt.day_name()\n# print(data_week)\ndate2week = dict(zip(test_data['date'].unique(), data_week))\nprint(date2week)","metadata":{"id":"xw_DSSu54RUh","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"answer = []\nalpha = 0.14\nalpha = 1\nbeta = 1\nfor product_info in tqdm(test_data[['warehouse_id', 'product_id', 'date']].values):\n    id_warehouse = (product_info[0])\n    id_product = (product_info[1])\n    id_date = (product_info[2])\n\n    data = my_huge_dict[id_warehouse][id_product][date2week[id_date]].copy()\n    local_max = 0\n    local_i = 0\n    for i in range(len(data)):\n        if local_max < data[i]:\n            local_max = data[i]\n            local_i = i\n\n    data[local_i] = data[-1]  # Удаление максимального элемента\n    data.pop()\n    #right_answer.append(my_huge_dict_test[id_warehouse][id_product][date2week[id_date]][0])\n    my_ans_by_day = math.floor(exponential_smoothing(data, 0.14))\n\n    if date2week[id_date] == 'Saturday':\n        answer.append(my_ans_by_day)\n    \n    #-----------------------------------\n    elif date2week[id_date] == 'Friday':\n        data2 = my_huge_dict[id_warehouse][id_product]['Sunday'].copy()\n        my_ans_by_second_day = math.floor(exponential_smoothing(data2, 0.14))\n        answer.append((my_ans_by_day * alpha + my_ans_by_second_day * beta) / (alpha + beta))\n    \n    elif date2week[id_date] == 'Sunday':\n        data2 = my_huge_dict[id_warehouse][id_product]['Friday'].copy()\n        my_ans_by_second_day = math.floor(exponential_smoothing(data2, 0.14))\n        answer.append((my_ans_by_day * alpha + my_ans_by_second_day * beta) / (alpha + beta))\n    \n    #-----------------------------------\n    elif date2week[id_date] == 'Monday':\n        data2 = my_huge_dict[id_warehouse][id_product]['Tuesday'].copy()\n        my_ans_by_second_day = math.floor(exponential_smoothing(data2, 0.14))\n        answer.append((my_ans_by_day * alpha + my_ans_by_second_day * beta) / (alpha + beta))\n    \n    elif date2week[id_date] == 'Tuesday':\n        data2 = my_huge_dict[id_warehouse][id_product]['Monday'].copy()\n        my_ans_by_second_day = math.floor(exponential_smoothing(data2, 0.14))\n        answer.append((my_ans_by_day * alpha + my_ans_by_second_day * beta) / (alpha + beta))\n    \n    #-----------------------------------\n    elif date2week[id_date] == 'Wednesday':\n        data2 = my_huge_dict[id_warehouse][id_product]['Thursday'].copy()\n        my_ans_by_second_day = math.floor(exponential_smoothing(data2, 0.14))\n        answer.append((my_ans_by_day * alpha + my_ans_by_second_day * beta) / (alpha + beta))\n    \n    elif date2week[id_date] == 'Thursday':\n        data2 = my_huge_dict[id_warehouse][id_product]['Wednesday'].copy()\n        my_ans_by_second_day = math.floor(exponential_smoothing(data2, 0.14))\n        answer.append((my_ans_by_day * alpha + my_ans_by_second_day * beta) / (alpha + beta))\n    \nprint()\nprint(len(answer), len(simple_data))","metadata":{"id":"osulJB684RRq","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Result_table = pd.read_csv(\"/content/drive/MyDrive/Sales_Forecasting/sub.csv\")\n#Result_table['quantity'] = pd.Series(answer)\n#Result_table[[\"id\", \"quantity\"]].to_csv(\"FINAL_3.csv\", index=False)","metadata":{"id":"R_mMNa174RPl","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Score = 0.20137\n### Хуже чем прошлая попытка... Явно есть ошибка","metadata":{"id":"xq1ezrezDH97"}},{"cell_type":"markdown","source":"### Забыл округлить... Давайте перебеём параметры заново.","metadata":{"id":"tRA7MBWbE_QB"}},{"cell_type":"code","source":"data_ = pd.Series(pd.to_datetime(test_data['date'].unique()))\n\n\n#print(data_, type(data_))\ndata_week = data_.dt.day_name()\n# print(data_week)\ndate2week = dict(zip(test_data['date'].unique(), data_week))\nprint(date2week)","metadata":{"id":"U-EO2rq6D5lX","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"answer = []\nalpha = 0.14\nalpha = 1\nbeta = 1\nfor product_info in tqdm(test_data[['warehouse_id', 'product_id', 'date']].values):\n    id_warehouse = (product_info[0])\n    id_product = (product_info[1])\n    id_date = (product_info[2])\n\n    data = my_huge_dict[id_warehouse][id_product][date2week[id_date]].copy()\n    local_max = 0\n    local_i = 0\n    for i in range(len(data)):\n        if local_max < data[i]:\n            local_max = data[i]\n            local_i = i\n\n    data[local_i] = data[-1]  # Удаление максимального элемента\n    data.pop()\n    #right_answer.append(my_huge_dict_test[id_warehouse][id_product][date2week[id_date]][0])\n    my_ans_by_day = math.floor(exponential_smoothing(data, 0.14))\n\n    if date2week[id_date] == 'Saturday':\n        answer.append(my_ans_by_day)\n    \n    #-----------------------------------\n    elif date2week[id_date] == 'Friday':\n        data2 = my_huge_dict[id_warehouse][id_product]['Sunday'].copy()\n        my_ans_by_second_day = math.floor(exponential_smoothing(data2, 0.14))\n        answer.append(math.floor((my_ans_by_day * alpha + my_ans_by_second_day * beta) / (alpha + beta)))\n    \n    elif date2week[id_date] == 'Sunday':\n        data2 = my_huge_dict[id_warehouse][id_product]['Friday'].copy()\n        my_ans_by_second_day = math.floor(exponential_smoothing(data2, 0.14))\n        answer.append(math.floor((my_ans_by_day * alpha + my_ans_by_second_day * beta) / (alpha + beta)))\n    \n    #-----------------------------------\n    elif date2week[id_date] == 'Monday':\n        data2 = my_huge_dict[id_warehouse][id_product]['Tuesday'].copy()\n        my_ans_by_second_day = math.floor(exponential_smoothing(data2, 0.14))\n        answer.append(math.floor((my_ans_by_day * alpha + my_ans_by_second_day * beta) / (alpha + beta)))\n    \n    elif date2week[id_date] == 'Tuesday':\n        data2 = my_huge_dict[id_warehouse][id_product]['Monday'].copy()\n        my_ans_by_second_day = math.floor(exponential_smoothing(data2, 0.14))\n        answer.append(math.floor((my_ans_by_day * alpha + my_ans_by_second_day * beta) / (alpha + beta)))\n    \n    #-----------------------------------\n    elif date2week[id_date] == 'Wednesday':\n        data2 = my_huge_dict[id_warehouse][id_product]['Thursday'].copy()\n        my_ans_by_second_day = math.floor(exponential_smoothing(data2, 0.14))\n        answer.append(math.floor((my_ans_by_day * alpha + my_ans_by_second_day * beta) / (alpha + beta)))\n    \n    elif date2week[id_date] == 'Thursday':\n        data2 = my_huge_dict[id_warehouse][id_product]['Wednesday'].copy()\n        my_ans_by_second_day = math.floor(exponential_smoothing(data2, 0.14))\n        answer.append(math.floor((my_ans_by_day * alpha + my_ans_by_second_day * beta) / (alpha + beta)))\n    \nprint()\nprint(len(answer), len(simple_data))","metadata":{"id":"FW3-HTzrGY2n","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Result_table = pd.read_csv(\"../input/grocery-sales-forecast/sub.csv\")\nResult_table['quantity'] = pd.Series(answer)\nResult_table[[\"id\", \"quantity\"]].to_csv(\"FINAL_33.csv\", index=False)","metadata":{"id":"xCIpfDIHGYz4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Score = 0.19921\n### Потянет","metadata":{"id":"9Tfj1a6JHbpy"}},{"cell_type":"markdown","source":"## Финальная попытка усовершенствовать результат\n","metadata":{"id":"T-u3tTUFYnEJ"}},{"cell_type":"markdown","source":"### Пробуем 2 идеи:\n\n*   Аккуратнее обрабатывать выбросы\n*   Попробовать другую группировку дней\n\n","metadata":{"id":"mxUovcphYy_G"}},{"cell_type":"code","source":"data_ = pd.Series(pd.to_datetime(train_data['date'].unique()))\n\n# print(data_, type(data_))\ndata_week = data_.dt.day_name()\n# print(data_week)\ndate2week = dict(zip(train_data['date'].unique(), data_week))\nprint(date2week)","metadata":{"id":"ly6iX-59GYyL","outputId":"7003a2f6-e1a2-4ac9-f66d-2bbbc2c81e7d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"right_answer = []\nanswer_round, answer_floor, answer_ceil = [], [], []\nanswer_median, answer_median_low, answer_median_high = [], [], []\nanswer_mode, answer_exp = [], []\nthreshold  = 1.5\nfor id_warehouse in warehouse_id:\n    for id_product in tqdm(product_id):\n        for id_date in date:\n            data = my_huge_dict_train[id_warehouse][id_product][date2week[id_date]].copy()\n            local_max = 0\n            local_i = 0\n            for i in range(len(data)):\n                if local_max < data[i]:\n                    local_max = data[i]\n                    local_i = i\n            \n            if local_max > threshold * math.floor(sum(data)/len(data)):\n                data[local_i] = data[-1]  # Удаление максимального элемента\n                data.pop()\n            else:\n                data[local_i] = data[-1]  # Удаление максимального элемента\n                data.pop()\n\n\n            right_answer.append(my_huge_dict_test[id_warehouse][id_product][date2week[id_date]][0])\n            answer_round.append(round(sum(data)/len(data)))\n            answer_floor.append(math.floor(sum(data)/len(data)))\n            answer_ceil.append(math.ceil(sum(data)/len(data)))\n\n            answer_median.append(statistics.median(data))\n            answer_median_low.append(statistics.median_low(data))\n            answer_median_high.append(statistics.median_high(data))\n            \n            answer_exp.append(math.floor(exponential_smoothing(data, 0.14)))\n            #answer_mode.append(int(s.mode(data)[0]))\n\nprint(mean_absolute_error(right_answer, answer_round))\nprint(mean_absolute_error(right_answer, answer_floor))\nprint(mean_absolute_error(right_answer, answer_ceil))\n\nprint(mean_absolute_error(right_answer, answer_median))\nprint(mean_absolute_error(right_answer, answer_median_low))\nprint(mean_absolute_error(right_answer, answer_median_high))\n\nprint(mean_absolute_error(right_answer, answer_exp))\n#print(mean_absolute_error(right_answer, answer_mode))","metadata":{"id":"_DNJi6FHGYwE","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cur_min = 1\nalpha = 1\nbeta = 1\nbest_threshold = 1\nA, B = [], []\nfor koef in tqdm(range(53, 72)):\n    threshold = koef/10\n    right_answer = []\n    answer_exp = []\n    for id_warehouse in warehouse_id:\n        for id_product in (product_id):\n            for id_date in date:\n                data = my_huge_dict_train[id_warehouse][id_product][date2week[id_date]].copy()\n                local_max = 0\n                local_i = 0\n                for i in range(len(data)):\n                    if local_max < data[i]:\n                        local_max = data[i]\n                        local_i = i\n\n                if local_max > threshold * math.floor(sum(data)/len(data)):\n                    data[local_i] = data[-1]  # Удаление максимального элемента\n                    data.pop()\n\n                right_answer.append(my_huge_dict_test[id_warehouse][id_product][date2week[id_date]][0])\n                my_ans_by_day = math.floor(exponential_smoothing(data, 0.14))\n\n                if date2week[id_date] == 'Saturday':\n                    answer_exp.append(my_ans_by_day)\n                \n                #-----------------------------------\n                elif date2week[id_date] == 'Friday':\n                    data2 = my_huge_dict_train[id_warehouse][id_product]['Sunday'].copy()\n                    my_ans_by_second_day = math.floor(exponential_smoothing(data2, 0.14))\n                    answer_exp.append(math.floor((my_ans_by_day * alpha + my_ans_by_second_day * beta) / (alpha + beta)))\n                \n                elif date2week[id_date] == 'Sunday':\n                    data2 = my_huge_dict_train[id_warehouse][id_product]['Friday'].copy()\n                    my_ans_by_second_day = math.floor(exponential_smoothing(data2, 0.14))\n                    answer_exp.append(math.floor((my_ans_by_day * alpha + my_ans_by_second_day * beta) / (alpha + beta)))\n                \n                #-----------------------------------\n                elif date2week[id_date] == 'Monday':\n                    data2 = my_huge_dict_train[id_warehouse][id_product]['Tuesday'].copy()\n                    my_ans_by_second_day = math.floor(exponential_smoothing(data2, 0.14))\n                    answer_exp.append(math.floor((my_ans_by_day * alpha + my_ans_by_second_day * beta) / (alpha + beta)))\n                \n                elif date2week[id_date] == 'Tuesday':\n                    data2 = my_huge_dict_train[id_warehouse][id_product]['Monday'].copy()\n                    my_ans_by_second_day = math.floor(exponential_smoothing(data2, 0.14))\n                    answer_exp.append(math.floor((my_ans_by_day * alpha + my_ans_by_second_day * beta) / (alpha + beta)))\n                \n                #-----------------------------------\n                elif date2week[id_date] == 'Wednesday':\n                    data2 = my_huge_dict_train[id_warehouse][id_product]['Thursday'].copy()\n                    my_ans_by_second_day = math.floor(exponential_smoothing(data2, 0.14))\n                    answer_exp.append(math.floor((my_ans_by_day * alpha + my_ans_by_second_day * beta) / (alpha + beta)))\n                \n                elif date2week[id_date] == 'Thursday':\n                    data2 = my_huge_dict_train[id_warehouse][id_product]['Wednesday'].copy()\n                    my_ans_by_second_day = math.floor(exponential_smoothing(data2, 0.14))\n                    answer_exp.append(math.floor((my_ans_by_day * alpha + my_ans_by_second_day * beta) / (alpha + beta)))\n\n    if mean_absolute_error(right_answer, answer_exp) < cur_min:\n        best_threshold = threshold\n        cur_min = mean_absolute_error(right_answer, answer_exp)\n    \n    A.append(mean_absolute_error(right_answer, answer_exp))\n    B.append(threshold)\nprint()\nprint(cur_min, best_threshold)\nfig = plt.figure(figsize=(20, 10))\nax = fig.add_subplot(111)\nax.plot(B, A, color='orange')\nplt.show()","metadata":{"id":"8bB4dkC3GYuA","outputId":"a67bc530-7a79-4084-e5c9-c61d99229f21","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Окей, это пока лучший результат. Оставим threshold = 5.5","metadata":{"id":"fldtO6WMoV1w"}},{"cell_type":"markdown","source":"### Попробуем сгруппировать другим образом:\n\n*   Сб, вс-пн, вт-ср, чт-пт\n*   Для каждого дня будем учитывать предыдущий, минуя субботу\n*   Для каждого дня будем учитывать предыдущий, включая субботу\n\nПока 0.19406065345846368 лучший скор на наших данных\n","metadata":{"id":"y9mLCmT_psQL"}},{"cell_type":"code","source":"cur_min = 1\nalpha = 1\nbeta = 1\nthreshold = 5.5\nright_answer = []\nanswer_exp = []\nfor id_warehouse in warehouse_id:\n    for id_product in (product_id):\n        for id_date in date:\n            data = my_huge_dict_train[id_warehouse][id_product][date2week[id_date]].copy()\n            local_max = 0\n            local_i = 0\n            for i in range(len(data)):\n                if local_max < data[i]:\n                    local_max = data[i]\n                    local_i = i\n\n            if local_max > threshold * math.floor(sum(data)/len(data)):\n                data[local_i] = data[-1]  # Удаление максимального элемента\n                data.pop()\n\n            right_answer.append(my_huge_dict_test[id_warehouse][id_product][date2week[id_date]][0])\n            my_ans_by_day = math.floor(exponential_smoothing(data, 0.14))\n\n            if date2week[id_date] == 'Saturday':\n                answer_exp.append(my_ans_by_day)\n            \n            #-----------------------------------\n            elif date2week[id_date] == 'Friday':\n                data2 = my_huge_dict_train[id_warehouse][id_product]['Thursday'].copy()\n                my_ans_by_second_day = math.floor(exponential_smoothing(data2, 0.14))\n                answer_exp.append(math.floor((my_ans_by_day * alpha + my_ans_by_second_day * beta) / (alpha + beta)))\n            \n            elif date2week[id_date] == 'Thursday':\n                data2 = my_huge_dict_train[id_warehouse][id_product]['Friday'].copy()\n                my_ans_by_second_day = math.floor(exponential_smoothing(data2, 0.14))\n                answer_exp.append(math.floor((my_ans_by_day * alpha + my_ans_by_second_day * beta) / (alpha + beta)))\n            \n            #-----------------------------------\n            elif date2week[id_date] == 'Monday':\n                data2 = my_huge_dict_train[id_warehouse][id_product]['Sunday'].copy()\n                my_ans_by_second_day = math.floor(exponential_smoothing(data2, 0.14))\n                answer_exp.append(math.floor((my_ans_by_day * alpha + my_ans_by_second_day * beta) / (alpha + beta)))\n            \n            elif date2week[id_date] == 'Sunday':\n                data2 = my_huge_dict_train[id_warehouse][id_product]['Monday'].copy()\n                my_ans_by_second_day = math.floor(exponential_smoothing(data2, 0.14))\n                answer_exp.append(math.floor((my_ans_by_day * alpha + my_ans_by_second_day * beta) / (alpha + beta)))\n            \n            #-----------------------------------\n            elif date2week[id_date] == 'Wednesday':\n                data2 = my_huge_dict_train[id_warehouse][id_product]['Tuesday'].copy()\n                my_ans_by_second_day = math.floor(exponential_smoothing(data2, 0.14))\n                answer_exp.append(math.floor((my_ans_by_day * alpha + my_ans_by_second_day * beta) / (alpha + beta)))\n            \n            elif date2week[id_date] == 'Tuesday':\n                data2 = my_huge_dict_train[id_warehouse][id_product]['Wednesday'].copy()\n                my_ans_by_second_day = math.floor(exponential_smoothing(data2, 0.14))\n                answer_exp.append(math.floor((my_ans_by_day * alpha + my_ans_by_second_day * beta) / (alpha + beta)))\n\nprint()\nprint(mean_absolute_error(right_answer, answer_exp))\n","metadata":{"id":"kF_8b-Dco9ru","outputId":"8df734b6-d0c3-4a04-c1bb-e194146de432","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cur_min = 1\nalpha = 1\nbeta = 1\nthreshold = 5.5\nright_answer = []\nanswer_exp = []\nfor id_warehouse in warehouse_id:\n    for id_product in (product_id):\n        for id_date in date:\n            data = my_huge_dict_train[id_warehouse][id_product][date2week[id_date]].copy()\n            local_max = 0\n            local_i = 0\n            for i in range(len(data)):\n                if local_max < data[i]:\n                    local_max = data[i]\n                    local_i = i\n\n            if local_max > threshold * math.floor(sum(data)/len(data)):\n                data[local_i] = data[-1]  # Удаление максимального элемента\n                data.pop()\n\n            right_answer.append(my_huge_dict_test[id_warehouse][id_product][date2week[id_date]][0])\n            my_ans_by_day = math.floor(exponential_smoothing(data, 0.14))\n\n            if date2week[id_date] == 'Saturday':\n                answer_exp.append(my_ans_by_day)\n            \n            #-----------------------------------\n            elif date2week[id_date] == 'Friday':\n                data2 = my_huge_dict_train[id_warehouse][id_product]['Thursday'].copy()\n                my_ans_by_second_day = math.floor(exponential_smoothing(data2, 0.14))\n                answer_exp.append(math.floor((my_ans_by_day * alpha + my_ans_by_second_day * beta) / (alpha + beta)))\n            \n            elif date2week[id_date] == 'Thursday':\n                data2 = my_huge_dict_train[id_warehouse][id_product]['Wednesday'].copy()\n                my_ans_by_second_day = math.floor(exponential_smoothing(data2, 0.14))\n                answer_exp.append(math.floor((my_ans_by_day * alpha + my_ans_by_second_day * beta) / (alpha + beta)))\n            \n            #-----------------------------------\n            elif date2week[id_date] == 'Monday':\n                data2 = my_huge_dict_train[id_warehouse][id_product]['Sunday'].copy()\n                my_ans_by_second_day = math.floor(exponential_smoothing(data2, 0.14))\n                answer_exp.append(math.floor((my_ans_by_day * alpha + my_ans_by_second_day * beta) / (alpha + beta)))\n            \n            elif date2week[id_date] == 'Sunday':\n                data2 = my_huge_dict_train[id_warehouse][id_product]['Friday'].copy()\n                my_ans_by_second_day = math.floor(exponential_smoothing(data2, 0.14))\n                answer_exp.append(math.floor((my_ans_by_day * alpha + my_ans_by_second_day * beta) / (alpha + beta)))\n            \n            #-----------------------------------\n            elif date2week[id_date] == 'Wednesday':\n                data2 = my_huge_dict_train[id_warehouse][id_product]['Tuesday'].copy()\n                my_ans_by_second_day = math.floor(exponential_smoothing(data2, 0.14))\n                answer_exp.append(math.floor((my_ans_by_day * alpha + my_ans_by_second_day * beta) / (alpha + beta)))\n            \n            elif date2week[id_date] == 'Tuesday':\n                data2 = my_huge_dict_train[id_warehouse][id_product]['Monday'].copy()\n                my_ans_by_second_day = math.floor(exponential_smoothing(data2, 0.14))\n                answer_exp.append(math.floor((my_ans_by_day * alpha + my_ans_by_second_day * beta) / (alpha + beta)))\n\nprint()\nprint(mean_absolute_error(right_answer, answer_exp))\n","metadata":{"id":"qnke6yBIo9nx","outputId":"433ce7b8-d915-44f4-9b25-844007d9dfc7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cur_min = 1\nalpha = 1\nbeta = 1\nthreshold = 5.5\nright_answer = []\nanswer_exp = []\nfor id_warehouse in warehouse_id:\n    for id_product in (product_id):\n        for id_date in date:\n            data = my_huge_dict_train[id_warehouse][id_product][date2week[id_date]].copy()\n            local_max = 0\n            local_i = 0\n            for i in range(len(data)):\n                if local_max < data[i]:\n                    local_max = data[i]\n                    local_i = i\n\n            if local_max > threshold * math.floor(sum(data)/len(data)):\n                data[local_i] = data[-1]  # Удаление максимального элемента\n                data.pop()\n\n            right_answer.append(my_huge_dict_test[id_warehouse][id_product][date2week[id_date]][0])\n            my_ans_by_day = math.floor(exponential_smoothing(data, 0.14))\n\n            if date2week[id_date] == 'Saturday':\n                data2 = my_huge_dict_train[id_warehouse][id_product]['Friday'].copy()\n                my_ans_by_second_day = math.floor(exponential_smoothing(data2, 0.14))\n                answer_exp.append(math.floor((my_ans_by_day * alpha + my_ans_by_second_day * beta) / (alpha + beta)))\n            \n            #-----------------------------------\n            elif date2week[id_date] == 'Friday':\n                data2 = my_huge_dict_train[id_warehouse][id_product]['Thursday'].copy()\n                my_ans_by_second_day = math.floor(exponential_smoothing(data2, 0.14))\n                answer_exp.append(math.floor((my_ans_by_day * alpha + my_ans_by_second_day * beta) / (alpha + beta)))\n            \n            elif date2week[id_date] == 'Thursday':\n                data2 = my_huge_dict_train[id_warehouse][id_product]['Wednesday'].copy()\n                my_ans_by_second_day = math.floor(exponential_smoothing(data2, 0.14))\n                answer_exp.append(math.floor((my_ans_by_day * alpha + my_ans_by_second_day * beta) / (alpha + beta)))\n            \n            #-----------------------------------\n            elif date2week[id_date] == 'Monday':\n                data2 = my_huge_dict_train[id_warehouse][id_product]['Sunday'].copy()\n                my_ans_by_second_day = math.floor(exponential_smoothing(data2, 0.14))\n                answer_exp.append(math.floor((my_ans_by_day * alpha + my_ans_by_second_day * beta) / (alpha + beta)))\n            \n            elif date2week[id_date] == 'Sunday':\n                data2 = my_huge_dict_train[id_warehouse][id_product]['Saturday'].copy()\n                my_ans_by_second_day = math.floor(exponential_smoothing(data2, 0.14))\n                answer_exp.append(math.floor((my_ans_by_day * alpha + my_ans_by_second_day * beta) / (alpha + beta)))\n            \n            #-----------------------------------\n            elif date2week[id_date] == 'Wednesday':\n                data2 = my_huge_dict_train[id_warehouse][id_product]['Tuesday'].copy()\n                my_ans_by_second_day = math.floor(exponential_smoothing(data2, 0.14))\n                answer_exp.append(math.floor((my_ans_by_day * alpha + my_ans_by_second_day * beta) / (alpha + beta)))\n            \n            elif date2week[id_date] == 'Tuesday':\n                data2 = my_huge_dict_train[id_warehouse][id_product]['Monday'].copy()\n                my_ans_by_second_day = math.floor(exponential_smoothing(data2, 0.14))\n                answer_exp.append(math.floor((my_ans_by_day * alpha + my_ans_by_second_day * beta) / (alpha + beta)))\n\nprint()\nprint(mean_absolute_error(right_answer, answer_exp))\n","metadata":{"id":"lEnRRgtmo9lL","outputId":"afc6da32-03e8-458b-b514-6d1119b8503b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Такс, ну субботу включать всё-таки не нужно, а вот идея с предыдущим днём стрельнула. На этом и остановлюсь, ибо тестировать группы по 3 дня это очень странная идея.","metadata":{"id":"z8mqh93LsApl"}},{"cell_type":"code","source":"data_ = pd.Series(pd.to_datetime(test_data['date'].unique()))\n\n\n#print(data_, type(data_))\ndata_week = data_.dt.day_name()\n# print(data_week)\ndate2week = dict(zip(test_data['date'].unique(), data_week))\nprint(date2week)","metadata":{"id":"oNbS2N5Ko9h8","outputId":"cf9ef854-6e99-49f6-ec68-16097a3d4522","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cur_min = 1\nalpha = 1\nbeta = 1\nthreshold = 5.5\nright_answer = []\nanswer_exp = []\nfor product_info in tqdm(test_data[['warehouse_id', 'product_id', 'date']].values):\n    id_warehouse = (product_info[0])\n    id_product = (product_info[1])\n    id_date = (product_info[2])\n\n    data = my_huge_dict[id_warehouse][id_product][date2week[id_date]].copy()\n    local_max = 0\n    local_i = 0\n    for i in range(len(data)):\n        if local_max < data[i]:\n            local_max = data[i]\n            local_i = i\n\n    if local_max > threshold * math.floor(sum(data)/len(data)):\n        data[local_i] = data[-1]  # Удаление максимального элемента\n        data.pop()\n\n    # right_answer.append(my_huge_dict_test[id_warehouse][id_product][date2week[id_date]][0])\n    my_ans_by_day = math.floor(exponential_smoothing(data, 0.14))\n\n    if date2week[id_date] == 'Saturday':\n        answer_exp.append(my_ans_by_day)\n    \n    #-----------------------------------\n    elif date2week[id_date] == 'Friday':\n        data2 = my_huge_dict_train[id_warehouse][id_product]['Thursday'].copy()\n        my_ans_by_second_day = math.floor(exponential_smoothing(data2, 0.14))\n        answer_exp.append(math.floor((my_ans_by_day * alpha + my_ans_by_second_day * beta) / (alpha + beta)))\n    \n    elif date2week[id_date] == 'Thursday':\n        data2 = my_huge_dict_train[id_warehouse][id_product]['Wednesday'].copy()\n        my_ans_by_second_day = math.floor(exponential_smoothing(data2, 0.14))\n        answer_exp.append(math.floor((my_ans_by_day * alpha + my_ans_by_second_day * beta) / (alpha + beta)))\n    \n    #-----------------------------------\n    elif date2week[id_date] == 'Monday':\n        data2 = my_huge_dict_train[id_warehouse][id_product]['Sunday'].copy()\n        my_ans_by_second_day = math.floor(exponential_smoothing(data2, 0.14))\n        answer_exp.append(math.floor((my_ans_by_day * alpha + my_ans_by_second_day * beta) / (alpha + beta)))\n    \n    elif date2week[id_date] == 'Sunday':\n        data2 = my_huge_dict_train[id_warehouse][id_product]['Friday'].copy()\n        my_ans_by_second_day = math.floor(exponential_smoothing(data2, 0.14))\n        answer_exp.append(math.floor((my_ans_by_day * alpha + my_ans_by_second_day * beta) / (alpha + beta)))\n    \n    #-----------------------------------\n    elif date2week[id_date] == 'Wednesday':\n        data2 = my_huge_dict_train[id_warehouse][id_product]['Tuesday'].copy()\n        my_ans_by_second_day = math.floor(exponential_smoothing(data2, 0.14))\n        answer_exp.append(math.floor((my_ans_by_day * alpha + my_ans_by_second_day * beta) / (alpha + beta)))\n    \n    elif date2week[id_date] == 'Tuesday':\n        data2 = my_huge_dict_train[id_warehouse][id_product]['Monday'].copy()\n        my_ans_by_second_day = math.floor(exponential_smoothing(data2, 0.14))\n        answer_exp.append(math.floor((my_ans_by_day * alpha + my_ans_by_second_day * beta) / (alpha + beta)))\n\nprint()\n# print(mean_absolute_error(right_answer, answer_exp))\nprint(len(answer_exp), len(simple_data))","metadata":{"id":"1Yc6MERRimVC","outputId":"2879275d-4d5d-4c44-b826-a5c568b7a4d0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Result_table = pd.read_csv(\"/content/drive/MyDrive/Sales_Forecasting/sub.csv\")\n#Result_table['quantity'] = pd.Series(answer_exp)\n#Result_table[[\"id\", \"quantity\"]].to_csv(\"Last_try.csv\", index=False)","metadata":{"id":"6fYNJAUwtfPl","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Score = 0.19935\n### Хуже, чем прошлая попытка. Грустно. Но ничего нового я уже пробовать не буду, ибо попыток не осталось.","metadata":{"id":"kvgtWs_3uuXE"}},{"cell_type":"code","source":"","metadata":{"id":"nF5T-6altteC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}